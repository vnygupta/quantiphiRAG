{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "41f4c843",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import HuggingFaceInstructEmbeddings,HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.llms import OpenAI, HuggingFaceHub\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.retrievers import EnsembleRetriever\n",
    "from langchain_community.retrievers import BM25Retriever\n",
    "from langchain import PromptTemplate, LLMChain\n",
    "from langchain.chains import RetrievalQA\n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e69c8ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_token='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'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6fc48ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'ConceptsofBiology.pdf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ada3393",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pdf(file_path,start_page,end_page):\n",
    "    loader = PyPDFLoader(file_path)\n",
    "    pages = loader.load_and_split()\n",
    "    documents = pages[start_page:end_page+1]\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=1000, chunk_overlap=200,separators=[\"\\n\\n\",\"\\n\",\" \",\"\"]\n",
    "    )\n",
    "    docs = text_splitter.split_documents(documents=documents)\n",
    "    return docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "800dd1d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load INSTRUCTOR_Transformer\n",
      "max_seq_length  512\n"
     ]
    }
   ],
   "source": [
    "# Get embedding model\n",
    "embeddings = HuggingFaceInstructEmbeddings(model_name=\"hkunlp/instructor-base\")\n",
    "Model=HuggingFaceHub(repo_id=\"mistralai/Mixtral-8x7B-Instruct-v0.1\",huggingfacehub_api_token=hf_token, model_kwargs={\"temperature\":0.7,\"max_legth\":500})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f26e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create vector database\n",
    "db = FAISS.from_documents(docs, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "26a226d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creaye Sparse Database\n",
    "bm25_retriever = BM25Retriever.from_documents(docs,k=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "7619dcb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "faiss_retriever=db.as_retriever(k=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "7abd9b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_retriever = EnsembleRetriever(\n",
    "    retrievers=[bm25_retriever, faiss_retriever], weights=[0.5, 0.5]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "490c429c",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "Don't try to make up an answer, if you don't know just say that you don't know.\n",
    "Answer in the same language the question was asked.\n",
    "Use only the following pieces of context to answer the question at the end.\n",
    "if relevant information is not availble in context just say no information availble to answer question\n",
    "\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "Answer:\"\"\"\n",
    "\n",
    "\n",
    "PROMPT = PromptTemplate(\n",
    "    template = prompt_template, \n",
    "    input_variables = [\"context\", \"question\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "772d22df",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm = Model,\n",
    "    chain_type = \"stuff\", # map_reduce, map_rerank, stuff, refine\n",
    "    retriever = ensemble_retriever, \n",
    "    chain_type_kwargs = {\"prompt\": PROMPT},\n",
    "    return_source_documents = False,\n",
    "    verbose = False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10e95379",
   "metadata": {},
   "source": [
    "## Gradio App"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "b7126c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_answer(query):\n",
    "    res = qa_chain.invoke( query)\n",
    "    return res['result'].split('\\nAnswer:')[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "0ef01597",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7871\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7871/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def respond(query):\n",
    "    response = get_answer(query)\n",
    "    return response\n",
    "\n",
    "iface = gr.Interface(\n",
    "    fn=respond,\n",
    "    inputs=\"text\",\n",
    "    outputs=\"text\",\n",
    "    title=\"Retrieval-Augmented Generation\"\n",
    ")\n",
    "iface.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f854891",
   "metadata": {},
   "source": [
    "## alternative way to do the RAG without using any library like Langchain,LLamaIndex or Haystack"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43be36f3",
   "metadata": {},
   "source": [
    "### Suggestion: PEFT LORA Based Adapter can be trained in new knowledege base and can be attched to the main model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faef9e2d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
